<!doctype html>
 
<html class="no-js" lang="en" >  
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1"> 
	<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
	<link rel="icon" type="image/x-icon" href="favicon.ico">
	<link rel="Bookmark" type="image/x-icon" href="favicon.ico">
	<link rel="apple-touch-icon" type="image/x-icon" href="favicon.png">
	<link rel="stylesheet" href="css/styles.css">  
	
	<title>Homepage of Huazhu FU</title>
	
</head>

<body> 
	<div id="wrapper"> 
		<section>
			<table border="0" id="table1" width="100%">
				<tbody>
					<tr> 
						<td>
							<h1> <a id="top-page" class="anchor" href="#top-page" aria-hidden="true"><span
								class="octicon octicon-link"></span></a>
								Huazhu FU</h1>
							<p>
								<b>Senior Scientist</b><br>
								<em> Institute of High Performance Computing (IHPC)<br>
								Agency for Science, Technology and Research (A*STAR), Singapore. </em>
							</p>
							<p>
								<b>Email:</b>  
								<em>hzfu(AT)ieee(DOT)org</em> 
							</p> 

							
						</td>  
						
						<!-- <td >
							<p align="left">
								<img border="0" src="sub_img/photo_hz.jpg" width="200">
							</p>

						</td>  -->
					</tr>
				</tbody>
			</table>

			<b>
				<a href="#new-page">[<ud>Recent News</ud>]</a> 
				- <a href="#Services-page">[<ud>Professional Activities</ud>]</a> 
				- <a href="#awards-pages">[<ud>Recognitions</ud>]</a>  
				- <a href="#Highlighted-Paper-pages">[<ud>Highlighted Publications</ud>]</a> 
				- <a href="#grants-pages">[<ud>Grants</ud>]</a>  
				- <a href="https://scholar.google.com/citations?hl=en&user=jCvUBYMAAAAJ" target="_blank">[<b><font color="#4285F4">G</font><font color="#DB4437">o</font><font color="#F4B400">o</font><font color="#4285F4">g</font><font color="#0F9D58">l</font><font color="#DB4437">e</font> Scholar</b>]</a> 
				
			</b>
			<hr />

			I am  a senior scientist at IHPC, A*STAR. 
			I received my Ph.D. from Tianjin University in 2013. 
			Previously, I were a Research Fellow (2013-2015) at Nanyang Technological University (NTU), Singapore, a Research Scientist (2015-2018) at Institute for Infocomm Research (I2R), A*STAR, Singapore, and a Senior Scientist (2018-2021) at Inception Institute of Artificial Intelligence (IIAI), UAE. 
			
			<br> 


			<strong>My research focuses on:</strong>  
				<li> <strong>Computer Vision:</strong> 
					Image Segmentation,  Image Enhancement, ⚡Efficient Learning. 
				</li> 
				<li> <strong>AI in Healthcare:</strong>
					Medical Image Analysis, Multi-modality Learning, ⚡Medical Foundation Model. 
				</li>
				<li> <strong>Trustworthy AI:</strong>  Responsible AI,
					⚡Uncertainty Estimation, ⚡Federated Learning. 
				</li> 
				

			<hr />

			<!-- Section: Open position --> 
			
			<table border="0" id="table1" width="100%">
				<tbody>
			<tr> 
				<td style="width:15%">
					<p align="left">
						<img border="0" src="sub_img/open-position-logo.png" width="120">
					</p>
				</td>
			
				<td > 
					<!-- <li>
						<b><hl_color>Scientist Position:</hl_color></b>
						We have several <a href="./job_poster.html" target="_blank"><b>Research Scientist Positions in AI for Healthcare and Trustworthy AI</b></a> available at IHPC, A*STAR, Singapore.  			  --> 
					<li>
						<b><hl_color>PhD Scholarships:</hl_color></b>
						<a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa" target="_blank"><b>Singapore International Graduate Award (SINGA) Scholarship</b></a> supports international students who wish to pursue their PhDs, collaborated with Singapore Universities (NUS, NTU, and SUTD). 
					</li>  
					<li>
						<b><hl_color>Visiting PhD Student:</hl_color></b> 
						<a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme" target="_blank"><b>A*STAR Research Attachment Programme (ARAP)</b></a> supports PhD students from overseas universities to spend a minimum of one to a maximum of two years at A*STAR Research Institutes under the joint supervision.
					</li> 
					<li>
						<b><hl_color>Chinese PhD Student:</hl_color> (Only available for Year 2024)</b> 
						We are also looking for visiting PhD students from China to spend a minimum of one year at IHPC, under <a href="https://www.csc.edu.cn/chuguo" target="_blank"><b>Chinese CSC Scholarship</b></a>. 
						 <!-- <em><hl_color>Requirements:</hl_color> Due to the limited headcount, we have to narrow down the list as: <strong>1)</strong> Having at least <strong>TWO</strong> first-author publications at top-tier conferences (e.g., CVPR, ICCV, ICLR) or journals (e.g., TPAMI, IJCV, TMI, TIP).
						<strong>2)</strong> Familiarity with one or more of the following will be viewed favorable: <strong>efficient learning</strong> (e.g., semi/self/weakly supervised learning, and domain adaptation), <strong>large foundation model</strong> (e.g., vision-language model, and generative model), and <strong>trustworthy AI</strong> (e.g., federated learning, uncertainty estimation, and explainable AI). </em> -->
					</li> 
			
				</td> 
			</tr>
			</tbody>
			</table>
			<hr/> 
 
			<!-- Section: Recent News: -->
			
			<h3>
				<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a> Recent News:
			</h3>

			<div style="height:500px; overflow-x:hidden;">
			<ul>   

				<li>[04/2023] <strong>Three papers</strong> accepted by <strong>ICML 2023</strong>.</li>
				<li>[04/2023] <strong>One paper</strong> for "MedPerf: Federated Benchmarking" accepted by <strong>Nature Machine Intelligence</strong>.</li>
				<li>[03/2023] The <strong>survey paper</strong>, "Transformers in Medical Imaging: A Survey", accepted by <strong>MedIA</strong>.</li>
				<li>[03/2023] <strong>One paper</strong> for "Medical Image Segmentation" accepted by <strong>IEEE TMI</strong>.</li>
				<li>[03/2023] <strong>One paper</strong> for "Co-saliency Detection" accepted by <strong>IEEE TPAMI</strong>.</li>
				<li>[03/2023] Glad to organize <strong>OMIA-X</strong> workshop with <strong>STAGE</strong> challenge on <strong>MICCAI 2023</strong>. </li>
				<li>[03/2023] Glad to organize <strong>REMIA</strong> workshop with <strong>ATLAS</strong> challenge on <strong>MICCAI 2023</strong>. </li> 
				<li>[02/2023] <strong>Two papers</strong> accepted by <strong>CVPR</strong>.</li>
				<li>[02/2023] <strong>One paper</strong> for "Multi-Contrast MRI Super-Resolution" accepted by <strong>IEEE TNNLS</strong>.</li>
				<li>[02/2023] <strong>One paper</strong> for "Fundus Image Enhancement" accepted by <strong>IEEE TMI</strong>.</li>
				<li>[01/2023] <strong>One paper</strong> for "Spatial Transcriptomics Representation Learning" accepted by <strong>Nature Communications</strong>.</li>
				<li>[01/2023] Serve as an Area Chair of <a href="https://conferences.miccai.org/2023/en/" target="_blank"><strong>MICCAI 2023</strong></a>. </li>
				<li>[01/2023] Be invited to serve as Associate Editor of <strong>IEEE TAI</strong>. </li>

				<li>------ <em>Happy New Year!</em> --------</li> 
				
				<li>[11/2022] <strong>One paper</strong> for "COVID-19 Semi-supervised Infection Segmentation" accepted by <strong>IEEE TCyb</strong>.</li>

				<li>[10/2022] Happy to be granted as Co-PI by <hl_grant>AISG Tech Challenge Funding</hl_grant>.</li>
				
				<li>[10/2022] Happy to be <hl_color>'Top 2% Scientists Worldwide'</hl_color>, identified by Stanford University, 2022. <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw" target="_blank">[link]</a></li>
				<li>[10/2022] <strong>One paper</strong> for "Medical Domain Adaptation" accepted by <strong>MedIA</strong>.</li>
				<li>[09/2022] Happy to receive the <hl_color>Best Paper Award</hl_color>  of Ophthalmic Medical Image Analysis Workshop in MICCAI, 2022. </li>
				<li>[09/2022] Happy to receive the <hl_color>Best Paper Runner-up Award</hl_color>  of Resource-Efficient Medical Image Analysis Workshop in MICCAI, 2022. </li>
				<li>[08/2022] <strong>One paper</strong> for "Federated learning on MR reconstruction" accepted by <strong>IEEE TMI</strong>. </li>
				<li>[07/2022] Happy to be granted as PI by <hl_grant>A*STAR Career Development Fund (CDF)</hl_grant>.</li>
				<li>[07/2022] <strong>One paper</strong> for "Video De-raining" accepted by <strong>ECCV 2022</strong>.</li>
				<li>[06/2022] Happy to be granted as PI by <hl_grant>A*STAR SERC Central Research Fund (CRF)</hl_grant>.</li>
				<li>[06/2022] <strong>One paper</strong> for "Multi-view learning" accepted by <strong>IEEE TNNLS</strong>.</li>
				<li>[06/2022] <strong>One paper</strong> for "Video Dehazing" accepted by <strong>ACM MM 2022</strong>.</li>
				<li>[06/2022] Be invited to serve as Associate Editor of <strong>IEEE TNNLS</strong>. </li>
				<li>[06/2022] <strong>Nine papers</strong> accepted by  <strong>MICCAI 2022</strong>. </li>
				<li>[05/2022] <strong>One paper</strong> for "Multi-Modal MR Reconstruction" accepted by <strong>IEEE TMI</strong>. </li>
				<li>[05/2022] <strong>One paper</strong> for "Lesion Segmentation in Fundus"  accepted by <strong>IEEE TMI</strong>. </li>
				<li>[05/2022] <strong>One paper</strong> for "Cataract classification in AS-OCT image" paper accepted by <strong>MedIA</strong>. </li>
				<li>[05/2022] Serve as Technical Program Committee member of  <a href="https://bhi-bsn-2022.org/" target="_blank"><strong>IEEE BHI 2022</strong></a>. </li>
				<li>[04/2022] <strong>One paper</strong> for "ADAM Challenge"  accepted by <strong>IEEE TMI</strong>. </li>
				<li>[04/2022] <strong>One paper</strong> for "Trustworthy Multi-view Classification"  accepted by  <strong>IEEE TPAMI</strong>. </li>
				<li>[03/2022] Serve as an Area Chair of  <a href="https://2022.ieeeicip.org/" target="_blank"><strong>IEEE ICIP 2022</strong></a>. </li>
				<li>[03/2022] <strong>Four papers</strong> accepted by  <strong>CVPR 2022</strong>.</li>
				<li>[02/2022] Happy by organize two workshops on <strong>MICCAI 2022</strong>: OMIA9 and REMIA. </li>
				<li>[02/2022] Happy to be granted as Co-PI by <hl_grant> AISG Tech Challenge Funding</hl_grant>.</li>
				<li>[01/2022] <strong>One paper</strong> for <em>"Cataractous Fundus Restoration"</em> accepted by  <strong>IEEE TMI</strong>. </li> 
				<li>[01/2022] <strong>One paper</strong> for <em>"Motion Segmentation"</em> accepted by  <strong>IEEE TPAMI</strong>. </li>
				<li>[01/2022] Serve as an Area Chair of <a href="https://conferences.miccai.org/2022/en/" target="_blank"><strong>MICCAI 2022</strong></a>. </li>

				<!-- <li>------ <em>Happy New Year!</em> --------</li> 
				
				<li>[12/2021] <strong>One paper</strong> for <em>"RGB-D saliency detection"</em> accepted by <strong>IEEE TIP</strong>.
				</li>
				<li>[11/2021] Serve as an Area Chair of <a href="https://2022.midl.io/" target="_blank"><strong>MIDL 2022</strong></a>. 
				</li>
				<li>[11/2021] Happy to be granted as PI by <hl_grant> A*STAR AI3 HTPO Seed Fund</hl_grant>.</li>

				<li>[11/2021] Happy to be a member of the IEEE Bio Imaging and Signal Processing Technical Committee (<a href="https://signalprocessingsociety.org/community-involvement/bio-imaging-and-signal-processing/bisp-tc-home" target="_blank"><strong>BISP TC</strong></a>). 
				</li>
				
				<li>[09/2021] <strong>One paper</strong> for <em>"Anomaly Detection in Medical Image"</em> accepted by <strong>IEEE TMI</strong>.
				</li>
				<li>[09/2021] <strong>One paper</strong> for <em>"Trustworthy Multimodal Regression"</em> accepted by <strong>NeurIPS 2021</strong>.
				</li>
				<li>[09/2021] <strong>One paper</strong> for <em>"Angle-closure Assessment in AS-OCT"</em> accepted by <strong>IEEE TMI</strong>.
				</li>
				<li>[08/2021] <strong>One paper</strong> for <em>"Subspace Clustering"</em> accepted by <strong>IEEE TNNLS</strong>.
				</li>
				<li>[07/2021] <strong>One paper</strong> for <em>"Medical Image Enhancement"</em> accepted by <strong>IEEE TMI</strong>.
				</li>
				<li>[07/2021] <strong>4 papers</strong> accepted by <strong>ICCV 2021</strong>.</li>
				<li>[07/2021] Happy to receive the <hl_color><strong>Best Paper Award</strong></hl_color>  of <strong>IEEE ICME 2021</strong>! [<a href="https://2021.ieeeicme.org/best_paper_awards" target="_blank">Link</a>] </li>
				<li>[07/2021] <strong>One paper</strong> for <em>"Image Dehazing"</em> accepted by <strong>ACM MM 2021</strong>. 
				<li>[06/2021] <strong>5 papers</strong> accepted by  <strong>MICCAI 2021</strong>.  
				<li>[06/2021] <strong>One paper</strong> for <em>"MR Image Reconstruction"</em> accepted by <strong>IEEE TNNLS</strong>.
				</li>
				<li>[03/2021] <strong>2 papers</strong> (<em>"Co-saliency Detection"</em> and <em>"Video shadow
						Detection"</em>) accepted by  <strong>CVPR 2021</strong>.
				</li>
				<li>[02/2021] <strong>One paper</strong> for <em>"Co-saliency Detection"</em> accepted by  <strong>IEEE TPAMI</strong>.
				</li>
				<li>[01/2021] <strong>One paper</strong> for <em>"Breast Lesion Segmentation"</em> accepted by  <strong>MedIA</strong>.
				</li>
				<li>[01/2021] <strong>One paper</strong> for <em>"Fundus Image Analysis Survey"</em> accepted by <strong>MedIA</strong>.
				</li>
				<li>[01/2021] <strong>One paper</strong> for <em>"Uncertainty Estimation in Multi-view Learning"</em> accepted by  <strong>ICLR 2021</strong>.
				</li>
				<li>[01/2021] <strong>One paper</strong> for <em>"Saliency Detection Survey"</em>  accepted by <strong>IEEE TPAMI</strong>.
				</li> -->

			</ul>

		</div>

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />


			<h3>
				<a id="Services-page" class="anchor" href="#Services-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a>Professional Activities:
			</h3>
			<ul>
				<li><strong>Memberships:</strong>
					<ul>
						<li> IEEE Senior Member. </li>
						<li> Member of the IEEE Bio Imaging and Signal Processing Technical Committee (<a href="https://signalprocessingsociety.org/community-involvement/bio-imaging-and-signal-processing/bisp-tc-home" target="_blank"><strong>BISP TC</strong></a>). </li> 
					</ul> 
				</li>

				<li><strong>Associate Editor:</strong>
					<ul>
						<li> IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>, IF=11.037), 2020 - present. </li>
						<li> IEEE Transactions on Neural Networks and Learning Systems (<strong>IEEE TNNLS</strong>, IF=14.255), 2022 - present. </li>
						<li> IEEE Journal of Biomedical and Health Informatics (<strong>IEEE JBHI</strong>, IF=7.021), 2020 - present. </li>
						<li> IEEE Transactions on Artificial Intelligence (<strong>IEEE TAI</strong>), 2023 - present. </li>
						<li> Scientific Reports, 2021 - present. </li>
						<li> IEEE Access, 2018 - present. </li>
					</ul>
				</li>

				<li><strong>Guest Editor:</strong>
					<ul>
						<li> IEEE TMI, Special Issue on “<i>Geometric Deep Learning in Medical Imaging</i>”, 2022. [<a
								href="https://www.embs.org/wp-content/uploads/2021/02/TMI-CFP-GDL_final.pdf"
								target="_blank">Link</a>] 
						</li>
						<li> IEEE JBHI, Special Issue on “<i>Generative Adversarial Networks in Biomedical Image Computing</i>”, 2021. [<a
								href="https://www.embs.org/jbhi/generative-adversarial-networks-in-biomedical-image-computing/"
								target="_blank">Link</a>]</li>
						<li> IEEE JBHI, Special Issue on “<i>Ophthalmic Image Analysis and Informatics</i>”, 2020.
							[<a href="https://www.embs.org/jbhi/articles/special-issue-on-ophthalmic-image-analysis-and-informatics/"
								target="_blank">Link</a>]</li>
					</ul>
				</li>

				<li><strong>Area Chair/Senior-PC:</strong>
					<ul>
						<li>
							MICCAI (2021-2023), IJCAI (2021), ACM MM Asia (2021), AAAI (2022), MIDL (2022-2023), ICIP (2022-2023), BHI (2022), ICASSP (2023), ISBI (2023).
						</li>
					</ul>
				</li>


				<li><strong>Challenge Organizer:</strong>
					<ul>
						<li>
							"<strong>ATLAS</strong>: A Tumor and Liver Automatic Segmentation" with the MICCAI 2023. [<a href="https://atlas-challenge.u-bourgogne.fr" target="_blank">Link</a>] 
						</li>

						<li>
							"<strong>STAGE</strong>: Structural-Functional Transition in Glaucoma Assessment" with the MICCAI 2023. [<a href="https://aistudio.baidu.com/aistudio/competition/detail/968/0/introduction" target="_blank">Link</a>]
						</li>

						<li>
							"<strong>GOALS</strong>: Glaucoma Oct Analysis and Layer Segmentation" with the MICCAI 2022.
							[<a href="https://aistudio.baidu.com/aistudio/competition/detail/230/0/introduction" target="_blank">Link</a>] 
						</li>
						<li>
							"<strong>GAMMA</strong>: Glaucoma Grading from Multi-Modality Images Challenge" with the MICCAI 2021.
							[<a href="https://gamma.grand-challenge.org/" target="_blank">Link</a>] 
							[<a href="https://arxiv.org/abs/2202.06511" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>REFUGE2</strong>: 2nd Retinal Fundus Glaucoma Challenge" with the MICCAI 2020.
							[<a href="https://refuge.grand-challenge.org" target="_blank">Link</a>]
							[<a href="https://arxiv.org/abs/2202.08994" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>ADAM</strong>: Automatic Detection challenge on Age-related Macular degeneration" with the ISBI 2020.
							[<a href="https://amd.grand-challenge.org" target="_blank">Link</a>]
							[<a href="https://arxiv.org/abs/2202.07983" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>AGE</strong>: Angle closure Glaucoma Evaluation Challenge" with the MICCAI 2019.
							[<a href="https://age.grand-challenge.org/" target="_blank">Link</a>] 
							[<a href="https://arxiv.org/abs/2005.02258" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>PALM</strong>: PathologicAL Myopia detection from retinal images" with the ISBI 2019. [<a href="https://palm.grand-challenge.org" target="_blank">Link</a>] 
							[<a href="https://arxiv.org/abs/1910.03667" target="_blank">Data Summary</a>]
						</li>
						<li>
							"<strong>REFUGE</strong>: Retinal Fundus Glaucoma Challenge" with the MICCAI 2018. 
							[<a href="https://refuge.grand-challenge.org/" target="_blank">Link</a>]
							[<a href="https://arxiv.org/abs/1910.03667" target="_blank">Summary Paper</a>]
						</li>
					</ul>
				</li>
				<li><strong>Workshop Chair:</strong>
					<ul>
						<li>MICCAI Workshop on Ophthalmic Medical Image Analysis (<strong>OMIA</strong>), 2018 - 2023. 
						[<a href="https://sites.google.com/view/omiax/home" target="_blank">Link</a>]</li>
						<li>MICCAI Workshop on Resource-Efficient Medical Image Analysis (<strong>REMIA</strong>), 2022-2023. 
						[<a href="https://miccai-remia.github.io/" target="_blank">Link</a>] </li>
					</ul>
				</li>
			</ul>
			</p>

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />

			<h3>
				<a id="awards-pages" class="anchor" href="#awards-pages" aria-hidden="true" ><span class="octicon octicon-link"></span></a> Recognitions: 
			</h3>
			<ul> 
				<li>
					2022: <strong>Best Paper Award</strong> of Ophthalmic Medical Image Analysis Workshop in MICCAI. 
				</li>
				<li>
					2022: <strong>Best Paper Runner-up Award</strong> of Resource-Efficient Medical Image Analysis Workshop in MICCAI. 
				</li>
				<li>
					2021-2022: <strong>Top 2% Scientists Worldwide</strong>, identified by Stanford University.
					<a href="https://dx.doi.org/10.17632/btchxktzyw" target="_blank">[Link]</a>
				</li>
				<li>
					2021: <strong>Best Paper Award</strong> in IEEE International Conference on Multimedia & Expo (ICME). 
					<a href="http://2021.ieeeicme.org/2021.ieeeicme.org/best_paper_awards.html" target="_blank">[Link]</a>
				</li> 
				
				<li>
					2021: Finalist of the Young Scientist Publication Impact Award in MICCAI.
				</li>
				<li>
					2021: <strong>Most Influential Paper (Application) Award</strong> in Jittor Developer Conference.
				</li>
				<li>
					2020-2022: IEEE TMI Distinguished Reviewer Gold Level.
				</li>
				<li>
					2021: Outstanding Reviewer in CVPR.
				</li>
				<li>
					2014 China Computer Federation (CCF) Outstanding Dissertation Nomination.
					<a href="https://www.ccf.org.cn/c/2014-12-14/647609.shtml" target="_blank">[Link]</a>
				</li>

			</ul>
			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />

			<h3>
				<a id="Highlighted-Paper-pages" class="anchor" href="#Highlighted-Paper-pages" aria-hidden="true" ><span class="octicon octicon-link"></span></a> Highlighted Publications: 
			</h3>

				More publications in:
				<a href="./paper_list.html" target="_blank">[<b>More..</b>]</a> /
				<a href="https://scholar.google.com/citations?hl=en&user=jCvUBYMAAAAJ" target="_blank">[<strong><font color="#4285F4">G</font><font color="#DB4437">o</font><font color="#F4B400">o</font><font color="#4285F4">g</font><font color="#0F9D58">l</font><font color="#DB4437">e</font> Scholar</strong>]</a>  

			<ul>
				

			  <li>⚡<a href="https://arxiv.org/abs/2110.01406" target="_blank"><strong>"Federated Benchmarking of Medical Artificial Intelligence with MedPerf"</strong></a>, <br>
				A. Karargyris, R. Umeton, ...,  <strong>H. Fu</strong>, ..., S. Bakas, and P. Mattson,<br>
			  <i><strong>Nature Machine Intelligence</strong>, 2023, accepted.</i> 
			  <a href="https://github.com/mlcommons/medperf" target="_blank">[Code]</a> 
			</li> 
			  <li>⚡<a href="https://www.nature.com/articles/s41467-023-36796-3" target="_blank"><strong>"Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST"</strong></a>,<br>
				Y. Long, K. S. Ang, ..., <strong>H. Fu</strong>, ..., and J. Chen,<br>
			<i><strong>Nature Communications</strong>, 2023.</i> 
			<a href="https://github.com/JinmiaoChenLab/DeepST" target="_blank">[Code]</a> 
		  </li>

		  <li>⚡<a href="https://arxiv.org/abs/2205.15469" target="_blank"><strong>"GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector"</strong></a>,<br>
			P. Zheng, <strong>H. Fu</strong>, D.-P. Fan, Q. Fan, J. Qin, Y.-W. Tai, C.-K. Tang, and L. V. Gool,<br>  
			<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), to appear.</i>
			<a href="https://github.com/ZhengPeng7/GCoNet_plus" target="_blank">[Code]</a>
		  </li> 
		  
		  <li>⚡<a href="https://arxiv.org/abs/2201.09873" target="_blank"><strong>"Transformers in Medical Imaging: A Survey",
		</strong></a> <br>
		F. Shamshad, S. Khan, S. W.s Zamir, M. H. Khan, M. Hayat, F. S. Khan, and <strong>H. Fu</strong>,<br>
		<i>Medical Image Analysis (<strong>MedIA</strong>), 2023.</i>
		<a href="https://github.com/fahadshamshad/awesome-transformers-in-medical-imaging" target="_blank">[Project]</a>
	  </li>

			  <li>⚡<a href="https://arxiv.org/abs/2204.11423" target="_blank"><strong>"Trusted Multi-View Classification with Dynamic Evidential Fusion"</strong></a>,
				<br>
				Z. Han, C. Zhang, <strong>H. Fu</strong>, and J. T. Zhou,<br>
				<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2023.</i> 
				<a href="https://github.com/hanmenghan/TMC" target="_blank">[Code]</a>
			  </li>
			  
				<li><a href="https://arxiv.org/abs/2202.04861" target="_blank"><strong>"Consistency and Diversity induced Human Motion Segmentation"</strong></a>,<br>
					T. Zhou, <strong>H. Fu</strong>, C. Gong, L. Shao, F. Porikli, H. Ling, and J. Shen,</em><br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2023.</i>
					 
				  </li> 
			
				  
				<li><a href="https://arxiv.org/abs/2007.03380" target="_blank"><strong>"Re-thinking Co-Salient Object Detection"</strong></a>, <br>
					D.-P. Fan, T. Li, Z. Lin, G.-P. Ji, D. Zhang, M.-M. Cheng, <strong>H. Fu</strong>, and J. Shen, <br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2022.</i>
					
					<a href="https://dengpingfan.github.io/papers/[2021][TPAMI]CoSOD3k_Chinese.pdf" target="_blank">[Chinese
						version]</a> 
					<a href="https://github.com/DengPingFan/CoEGNet" target="_blank">[Code]</a>
				</li>

				<li><a href="https://arxiv.org/abs/1904.09146" target="_blank"><strong>"Salient Object Detection in the Deep Learning Era: An In-Depth Survey",</strong></a><br>
					W. Wang, Q. Lai, <strong>H. Fu</strong>, J. Shen, H. Ling, and R. Yang,<br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2022.</i>
					<a href="https://github.com/wenguanwang/SODsurvey" target="_blank">[Project]</a> <br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>) 
				</li>

				<li><a href="https://arxiv.org/abs/2011.06170" target="_blank"><strong>"Deep Partial Multi-View Learning"</strong></a>,<br>
					C. Zhang, Y. Cui, Z. Han, J. T. Zhou, <strong>H. Fu</strong>, and Q. Hu,<br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2022.</i>
					
					<a href="https://github.com/hanmenghan/CPM_Nets" target="_blank">[Code]</a> <br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>)
				</li>   

				<li><a href="https://arxiv.org/abs/2101.09864" target="_blank"><strong>"Applications of Deep Learning in Fundus Images: A Review"</strong></a>,<br>
					T. Li, W. Bo, C. Hu, H. Kang, H. Liu, K. Wang, and <strong>H. Fu</strong>,<br> 
					<i>Medical Image Analysis (<strong>MedIA</strong>), 2021.</i>
					
					<a href="https://github.com/nkicsl/Fundus_Review" target="_blank">[Project]</a>
					<br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>)
				</li> 
 
				<li><a href="https://www.researchgate.net/publication/328479701_Generalized_Latent_Multi-View_Subspace_Clustering" target="_blank"><strong>"Generalized Latent Multi-view Subspace Clustering"</strong></a>,<br>
					C. Zhang, <strong>H. Fu</strong>, Q. Hu, X. Cao, Y. Xie, D. Tao, and
          D. Xu, <br> 
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2020.</i> 
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LMSC_CVPR2017_Zhang.rar">[Code]</a> 
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar">[Data]</a>
					<br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>)
				</li>  
					
				<li><a href="https://arxiv.org/abs/2004.14133" target="_blank"><strong>"Inf-Net: Automatic COVID-19 Lung Infection Segmentation from CT Images"</strong></a>,<br>
					D.-P. Fan, T. Zhou, G.-P. Ji, Y. Zhou, G. Chen, <strong>H. Fu</strong>, J. Shen, and L. Shao, <br>
					<i>IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2020.</i>
					
					<a href="https://github.com/DengPingFan/Inf-Net" target="_blank">[Code]</a>
					<br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>, 
					<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=wqLkMlos2DIJ.2022" target="_blank"><hl_color><em>Top-20 Most Cited Paper within 5 Years in IEEE TMI 2022</em></hl_color></a>, 
					<a href="https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=42" target="_blank"><hl_color><em>Top-50 Most Frequently Accessed Documents in IEEE TMI"</em></hl_color></a>)
				</li>  
 

				<li><a href="https://arxiv.org/abs/1903.02740" target="_blank"><strong>"CE-Net: Context Encoder Network for 2D Medical Image Segmentation"</strong></a>,<br>
					Z. Gu, J. Cheng, <strong>H. Fu</strong>, K. Zhou, H. Hao, Y. Zhao, T. Zhang, S. Gao, and J. Liu,<br>

					<i>IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2019.</i>
					
					<a href="https://github.com/Guzaiwang/CE-Net" target="_blank">[Code]</a>
					<br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>, 
					<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=wqLkMlos2DIJ.2022" target="_blank"><hl_color><em>Top-10 Most Cited Paper within 5 Years in IEEE TMI 2022</em></hl_color></a>,
					<a href="https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=42" target="_blank"><hl_color><em>Top-50 Most Frequently Accessed Documents in IEEE TMI"</em></hl_color></a>)
				</li> 

				<li><a href="https://arxiv.org/abs/1801.00926" target="_blank"><strong>"Joint Optic Disc and Cup Segmentation Based on Multi-label Deep Network and Polar
					Transformation"</strong></a>,<br>
					<strong>H. Fu</strong>, J. Cheng, Y. Xu, D. W. K. Wong, J. Liu, and X. Cao, <br>

					<i>IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2018.</i>
					
					<a href="https://github.com/HzFu/MNet_DeepCDR" target="_blank">[Code]</a>
					<br>
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>, 
					<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=wqLkMlos2DIJ.2022" target="_blank"><hl_color><em>Top-20 Most Cited Paper within 5 Years in IEEE TMI 2022</em></hl_color></a>)
				</li>  

			</ul> 

			 

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />
   
			<h3>
				<a id="grants-pages" class="anchor" href="#grants-pages" aria-hidden="true"><span
						class="octicon octicon-link"></span></a> Major Research Grants:
			</h3>

			<ul> 

				<li><b>Principal Investigator</b> (2022-2025), "Robust and Trustworthy AI system for Multi-modality Healthcare", <em>A*STAR SERC Central Research Fund</em>.
				</li>

				<li><b>Principal Investigator</b> (2022-2024): "Efficient and Robust Federated (Un)Learning for Utilizing Large Model on Resource-limited Clients", <em>A*STAR Career Development Fund</em>.
				</li>

				<li><b>Principal Investigator</b> (2022-2023): "Trustworthy and Data-efficient Multi-modality Learning for Healthcare", <em>A*STAR AI3 HTPO Seed Fund</em>.
				</li> 

				<li><b>Co-PI</b> (2022-2025): "SmartRx: Safe Medication Management Platform Augmented by ARTificial Intelligence for Prescribers [Rx]", <em>AISG Technology Challenge Funding</em>. 
				</li> 

				<li><b>Co-PI</b> (2022-2025): "RAPIER - Radiology Pathology Information Exchange Resource", <em>AISG Technology Challenge Funding</em>. 
				</li>  
			</ul>

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>

			<hr /> 



	<a href="https://www.revolvermaps.com/livestats/5c6hj26tc4d/"><img src="//rf.revolvermaps.com/h/m/a/0/ff0000/128/0/5c6hj26tc4d.png" width="256" height="128" alt="Map" style="border:0;"></a>

		</section>

	</div>
</body>

</html>
