<!doctype html>
 
<html class="no-js" lang="en" >  
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="chrome=1"> 
	<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
	<link rel="icon" type="image/x-icon" href="favicon.ico">
	<link rel="Bookmark" type="image/x-icon" href="favicon.ico">
	<link rel="apple-touch-icon" type="image/x-icon" href="favicon.png">
	<link rel="stylesheet" href="css/styles.css">  
	
	<title>Homepage of Huazhu FU</title>
	
</head>

<body> 
	<div id="wrapper"> 
		<section>
			<table border="0" id="table1" width="100%">
				<tbody>
					<tr> 
						<td>
							<h1> <a id="top-page" class="anchor" href="#top-page" aria-hidden="true"><span
								class="octicon octicon-link"></span></a>
								Huazhu FU</h1>
							<p>
								<b>Principal Scientist</b><br>
								<em> Institute of High Performance Computing (IHPC)<br>
								Agency for Science, Technology and Research (A*STAR), Singapore. </em>
							</p>
							<p>
								<b>Email:</b>  
								<em>hzfu(AT)ieee(DOT)org</em> 
							</p> 

							
						</td>  
						
						<!-- <td >
							<p align="left">
								<img border="0" src="sub_img/photo_hz.jpg" width="200">
							</p>

						</td>  -->
					</tr>
				</tbody>
			</table>

			<b>
				<a href="#new-page">[<ud>Recent News</ud>]</a> 
				- <a href="#Services-page">[<ud>Professional Activities</ud>]</a> 
				- <a href="#Highlighted-Paper-pages">[<ud>Highlighted Publications</ud>]</a> 
				- <a href="#awards-pages">[<ud>Recognitions & Awards</ud>]</a>   
				- <a href="https://scholar.google.com/citations?hl=en&user=jCvUBYMAAAAJ" target="_blank">[<b><font color="#4285F4">G</font><font color="#DB4437">o</font><font color="#F4B400">o</font><font color="#4285F4">g</font><font color="#0F9D58">l</font><font color="#DB4437">e</font> Scholar</b>]</a> 
				
			</b>
			<hr />

			I am  a principal scientist at IHPC, A*STAR. 
			I received my Ph.D. from Tianjin University in 2013. 
			Previously, I were a Research Fellow (2013-2015) at Nanyang Technological University (NTU), Singapore, a Research Scientist (2015-2018) at Institute for Infocomm Research (I2R), A*STAR, Singapore, and a Senior Scientist (2018-2021) at Inception Institute of Artificial Intelligence (IIAI), UAE. 
			
			<br> 


			<strong>Major focuses on:</strong>   
			<li> <strong>Computer Vision:</strong>  Foreground Detection, Image Segmentation, Image Restoration. 
			</li> 
				<li> <strong>AI for Healthcare:</strong>
					Medical Image Analysis, ⚡Medical Vision-Language Model, ⚡Medical Foundation Model. 
				</li>
				<li> <strong>Trustworthy AI:</strong> 
					⚡Uncertainty Estimation, ⚡Federated Learning. 
				</li> 
				

			<hr />

			<!-- Section: Open position 
				
				
				<table border="0" id="table1" width="100%">
				<tbody>
			<tr> 
				<td style="width:15%">
					<p align="left">
						<img border="0" src="sub_img/open-position-logo.png" width="120">
					</p>
				</td>
			
				<td > 
					 <li>
						<b><hl_color>Scientist Position:</hl_color></b>
						We have several <a href="./job_poster.html" target="_blank"><b>Research Scientist Positions in AI for Healthcare and Trustworthy AI</b></a> available at IHPC, A*STAR, Singapore.  			  
					<li>
						<b><hl_color>PhD Scholarships:</hl_color></b>
						<a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa" target="_blank"><b>Singapore International Graduate Award (SINGA) Scholarship</b></a> supports international students who wish to pursue their PhDs, collaborated with Singapore Universities (NUS, NTU, and SUTD). 
					</li>  
					<li>
						<b><hl_color>Visiting PhD Student:</hl_color></b> 
						<a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/a-star-research-attachment-programme" target="_blank"><b>A*STAR Research Attachment Programme (ARAP)</b></a> supports PhD students from overseas universities to spend a minimum of one to a maximum of two years at A*STAR Research Institutes under the joint supervision.
					</li> 
					<li>
						<b><hl_color>Chinese PhD Student:</hl_color></b> 
						We are also looking for visiting PhD students from China to spend a minimum of one year at IHPC, under <a href="https://www.csc.edu.cn/chuguo" target="_blank"><b>Chinese CSC Scholarship</b></a>. 
						<em><hl_color>Requirements:</hl_color> Due to the limited headcount, we have to narrow down the list as: <strong>1)</strong> Having at least <strong>TWO</strong> first-author publications at top-tier conferences (e.g., CVPR, ICCV, ICLR) or journals (e.g., TPAMI, IJCV, TMI, TIP).
						<strong>2)</strong> Familiarity with one or more of the following will be viewed favorable: <strong>efficient learning</strong> (e.g., semi/self/weakly supervised learning, and domain adaptation), <strong>large foundation model</strong> (e.g., vision-language model, and generative model), and <strong>trustworthy AI</strong> (e.g., federated learning, uncertainty estimation, and explainable AI). </em>  
					</li> 
			
				</td> 
			</tr>
			</tbody>
			</table>
			<hr/>  
		-->
 
			<!-- Section: Recent News: -->
			
			<h3>
				<a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a>
				<img src="sub_img/news-logo.gif" style="height:42px;"> Recent News :
			</h3>

			<div style="height:300px; overflow-x:hidden;">
			<ul>   

				<li>[10/2024] One paper accepted by <strong>Cell Reports Medicine</strong>: "Enhancing Al Reliability: A Foundation Model with Uncertainty Estimation for Optical Coherence Tomography based Retinal Diseases Diagnosis".</li>
				<li>[10/2024] One paper accepted by <strong>IEEE TMI</strong>: "CoD-MIL: Chain-of-Diagnosis Prompting Multiple Instance Learning for Whole Slide Image Classification".</li>
				<li>[20/2024] Happy to receive the <hl_color>Best Paper Award</hl_color>  of Ophthalmic Medical Image Analysis (OMIA) Workshop in MICCAI, 2024. </li>
				<li>[10/2024] One paper accepted by <strong>npj Digital Medicine</strong>: "Early Detection of Dementia through Retinal Imaging and Trustworthy AI".</li>
				<li>[09/2024] Two papers accepted by <strong>NeurIPS 2024</strong>.</li>
				<li>[09/2024] One paper accepted by <strong>EMNLP 2024</strong>: "Self-Training Large Language and Vision Assistant for Medical".</li>
				<li>[08/2024] One paper accepted by <strong>IEEE TPAMI</strong>: "Say No to Freeloader: Protecting Intellectual Property of Your Deep Model".</li>

				<li>[08/2024] One paper accepted by <strong>MedIA</strong>: "E2-MIL: An Explainable and Evidential Multiple Instance Learning Framework for Whole Slide Image Classification".</li>
				<li>[07/2024] One paper accepted by <strong>IEEE TPAMI</strong>: "Structure Unbiased Adversarial Model for Medical Image Translation".</li>

				<!-- 
				<li>[06/2024] 11 papers accepted by <strong>MICCAI 2024</strong>.</li> 
				<li>[05/2024] One paper accepted by <strong>MedIA</strong>: "Confidence-aware multi-modality learning for eye disease screening".</li>
				
				<li>[04/2024] Our paper, "Specificity-preserving RGB-D saliency detection", received the <hl_color>Honorable Mention Award</hl_color> of Computational Visual Media Journal in 2023.</li>
				<li>[04/2024] One paper accepted by <strong>IJCV</strong>: "ViDSOD-100: A New Dataset and A Baseline Model for RGB-D Video Salient Object Detection".</li>
				<li>[03/2024] One paper accepted by <strong>IEEE TMI</strong>: "Diverse Data Generation for Retinal Layer Segmentation with Potential Structure Modelling".</li>
				<li>[03/2024] One paper accepted by <strong>IEEE TMI</strong>: "Instrument-tissue Interaction Detection Framework for Surgical Video Understanding".</li> 
				<li>[02/2024] Two papers accepted by <strong>CVPR 2024</strong>.</li>
				<li>[01/2024] One paper accepted by <strong>Genome Medicine</strong>: "Unsupervised spatially embedded deep representation of spatial transcriptomics".</li> 
				<li>[01/2024] One paper accepted by <strong>IEEE TMI</strong>: "Geometric Correspondence-Based Multimodal Learning for Ophthalmic Image Analysis".</li>
				<li>[01/2024] Our PALM challenge paper accepted by <strong>Scientific Data</strong>: "Open Fundus Photograph Dataset with Pathologic Myopia Recognition and Anatomical Structure Annotation"</li>

				
				<li>[12/2023] One paper accepted by <strong>IEEE TMI</strong>: "Bilateral Supervision Network for Semi-supervised Medical Image Segmentation".</li>
				<li>[12/2023] One paper accepted by <strong>AAAI</strong> 2024.</li>
				<li>[12/2023] Our iChallenge datasets receive the <hl_color>Achievement Award</hl_color>  of  2023 TOP 100 Benchmarks & Evaluation by International Open Benchmark Council.</li>
				<li>[11/2023] One paper accepted by <strong>IEEE TMI</strong>: "Enhancing and Adapting in the Clinic: Source-free Unsupervised Domain Adaptation for Medical Image Enhancement".</li>
				<li>[11/2023] One paper accepted by <strong>IEEE TNNLS</strong>: "Federated Noisy Client Learning".</li>
				<li>[11/2023] One paper accepted by <strong>IEEE TMI</strong>: "Edge-guided Contrastive Adaptation Network for Arteriovenous Nicking Classification Using Synthetic Data".</li> 
				<li>[10/2023] Happy to receive the <hl_color>Best Paper Award</hl_color>  of  Distributed, Collaborative and Federated Learning (<strong>DeCAF</strong>) Workshop in MICCAI 2023:  "Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification". </li>
				<li>[10/2023] One paper accepted by <strong>Nature Communications</strong>: "Uncertainty-inspired Open Set Learning for Retinal Anomaly Identification".</li>
				<li>[09/2023] One paper accepted by <strong>NeurIPS 2023</strong>: "Fairness-guided Few-shot Prompting for Large Language Models".</li> 
				<li>[09/2023] One paper accepted by <strong>IEEE TMI</strong>: "MG-Trans: Multi-scale Graph Transformer with Information Bottleneck for Whole Slide Image Classification".</li> 
				<li>[08/2023] One paper accepted by <strong>MedIA</strong>: "A Generic Fundus Image Enhancement Network Boosted by Frequency Self-supervised Representation Learning".</li>
				<li>[08/2023] One GAMMA Challenge summary paper accepted by <strong>MedIA</strong>: "GAMMA Challenge: Glaucoma grAding from Multi-Modality imAges".</li>

				
				<li>[06/2023] One papers accepted by <strong>ICCV 2023</strong>.</li>
				<li>[06/2023] 16 papers accepted by <strong>MICCAI 2023</strong>.</li>
				<li>[04/2023] Three papers accepted by <strong>ICML 2023</strong>.</li>
				<li>[04/2023] One paper accepted by <strong>Nature Machine Intelligence</strong>: "Federated Benchmarking of Medical Artificial Intelligence with MedPerf".</li>
				<li>[03/2023] One survey paper accepted by <strong>MedIA</strong>: "Transformers in Medical Imaging: A Survey".</li> 
				<li>[03/2023] One paper accepted by <strong>IEEE TMI</strong>.</li>
				<li>[03/2023] One paper accepted by <strong>IEEE TPAMI</strong>: "GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector".</li>
				<li>[03/2023] Glad to organize <strong>OMIA-X</strong> workshop with <strong>STAGE</strong> challenge on <strong>MICCAI 2023</strong>. </li>
				<li>[03/2023] Glad to organize <strong>REMIA</strong> workshop with <strong>ATLAS</strong> challenge on <strong>MICCAI 2023</strong>. </li> 
				<li>[02/2023] Two papers accepted by <strong>CVPR</strong>.</li>
				<li>[02/2023] One paper accepted by <strong>IEEE TNNLS</strong>.</li>
				<li>[02/2023] One paper accepted by <strong>IEEE TMI</strong>.</li>
				<li>[01/2023] The paper accepted by <strong>Nature Communications</strong>: "Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST".</li>
				<li>[01/2023] Serve as an Area Chair of <a href="https://conferences.miccai.org/2023/en/" target="_blank"><strong>MICCAI 2023</strong></a>. </li>
				<li>[01/2023] Be invited to serve as Associate Editor of <strong>IEEE TAI</strong>. </li>
				
				
				<li>------ <em>Happy New Year!</em> --------</li> 
				
				<li>[11/2022] The paper,  "Dual Multi-scale Mean Teacher Network for Semi-supervised Infection Segmentation in Chest CT Volume for COVID-19",  accepted by <strong>IEEE TCyb</strong>.</li> 
				
				<li>[10/2022] Happy to be <hl_color>'Top 2% Scientists Worldwide'</hl_color>, identified by Stanford University, 2022. <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw" target="_blank">[link]</a></li>
				<li>[10/2022] The paper,  "Contrastive Domain Adaptation with Consistency Match for Automated Pneumonia Diagnosis", accepted by <strong>MedIA</strong>.</li>
				<li>[09/2022] Happy to receive the <hl_color>Best Paper Award</hl_color>  of Ophthalmic Medical Image Analysis Workshop in MICCAI, 2022. </li>
				<li>[09/2022] Happy to receive the <hl_color>Best Paper Runner-up Award</hl_color>  of Resource-Efficient Medical Image Analysis Workshop in MICCAI, 2022. </li>
				<li>[08/2022] The paper, "Specificity-Preserving Federated Learning for MR Image Reconstruction", accepted by <strong>IEEE TMI</strong>. </li>
				<li>[07/2022] Happy to be granted as <strong>PI</strong> by <hl_grant>A*STAR Career Development Fund (CDF)</hl_grant>.</li>
				<li>[07/2022] One paper accepted by <strong>ECCV 2022</strong>.</li>
			
				<li>[06/2022] The paper, "Autoencoder in Autoencoder Networks", accepted by <strong>IEEE TNNLS</strong>.</li>
				<li>[06/2022] One paper accepted by <strong>ACM MM 2022</strong>.</li>
				<li>[06/2022] Be invited to serve as Associate Editor of <strong>IEEE TNNLS</strong>. </li>
				<li>[06/2022] Nine papers accepted by  <strong>MICCAI 2022</strong>. </li>

				<li>[05/2022] One paper for "Multi-Modal MR Reconstruction" accepted by <strong>IEEE TMI</strong>. </li>
				<li>[05/2022] One paper for "Lesion Segmentation in Fundus"  accepted by <strong>IEEE TMI</strong>. </li>
				<li>[05/2022] One paper for "Cataract classification in AS-OCT image" paper accepted by <strong>MedIA</strong>. </li>
				<li>[05/2022] Serve as Technical Program Committee member of  <a href="https://bhi-bsn-2022.org/" target="_blank"><strong>IEEE BHI 2022</strong></a>. </li>
				<li>[04/2022] One paper for "ADAM Challenge"  accepted by <strong>IEEE TMI</strong>. </li>
				<li>[04/2022] One paper for "Trustworthy Multi-view Classification"  accepted by  <strong>IEEE TPAMI</strong>. </li>
				<li>[03/2022] Serve as an Area Chair of  <a href="https://2022.ieeeicip.org/" target="_blank"><strong>IEEE ICIP 2022</strong></a>. </li>
				<li>[03/2022] Four papers accepted by  <strong>CVPR 2022</strong>.</li>
				<li>[02/2022] Happy by organize two workshops on <strong>MICCAI 2022</strong>: OMIA9 and REMIA. </li>
				<li>[02/2022] Happy to be granted as Co-PI by <hl_grant> AISG Tech Challenge Funding</hl_grant>.</li> 
				<li>[01/2022] One paper for <em>"Cataractous Fundus Restoration"</em> accepted by  <strong>IEEE TMI</strong>. </li> 
				<li>[01/2022] One paper for <em>"Motion Segmentation"</em> accepted by  <strong>IEEE TPAMI</strong>. </li>
				<li>[01/2022] Serve as an Area Chair of <a href="https://conferences.miccai.org/2022/en/" target="_blank"><strong>MICCAI 2022</strong></a>. </li>

				<li>------ <em>Happy New Year!</em> --------</li> 
				
				<li>[12/2021] One paper for <em>"RGB-D saliency detection"</em> accepted by <strong>IEEE TIP</strong>.
				</li>
				<li>[11/2021] Serve as an Area Chair of <a href="https://2022.midl.io/" target="_blank"><strong>MIDL 2022</strong></a>. 
				</li> 

				<li>[11/2021] Happy to be a member of the IEEE Bio Imaging and Signal Processing Technical Committee (<a href="https://signalprocessingsociety.org/community-involvement/bio-imaging-and-signal-processing/bisp-tc-home" target="_blank"><strong>BISP TC</strong></a>). 
				</li>
				
				<li>[09/2021] One paper for <em>"Anomaly Detection in Medical Image"</em> accepted by <strong>IEEE TMI</strong>.
				</li>
				<li>[09/2021] One paper for <em>"Trustworthy Multimodal Regression"</em> accepted by <strong>NeurIPS 2021</strong>.
				</li>
				<li>[09/2021] One paper for <em>"Angle-closure Assessment in AS-OCT"</em> accepted by <strong>IEEE TMI</strong>.
				</li>
				<li>[08/2021] One paper for <em>"Subspace Clustering"</em> accepted by <strong>IEEE TNNLS</strong>.
				</li>
				<li>[07/2021] One paper for <em>"Medical Image Enhancement"</em> accepted by <strong>IEEE TMI</strong>.
				</li>
				<li>[07/2021] <strong>4 papers</strong> accepted by <strong>ICCV 2021</strong>.</li>
				<li>[07/2021] Happy to receive the <hl_color><strong>Best Paper Award</strong></hl_color>  of <strong>IEEE ICME 2021</strong>! [<a href="https://2021.ieeeicme.org/best_paper_awards" target="_blank">Link</a>] </li>
				<li>[07/2021] One paper for <em>"Image Dehazing"</em> accepted by <strong>ACM MM 2021</strong>. 
				<li>[06/2021] <strong>5 papers</strong> accepted by  <strong>MICCAI 2021</strong>.  
				<li>[06/2021] One paper for <em>"MR Image Reconstruction"</em> accepted by <strong>IEEE TNNLS</strong>.
				</li>
				<li>[03/2021] <strong>2 papers</strong> (<em>"Co-saliency Detection"</em> and <em>"Video shadow
						Detection"</em>) accepted by  <strong>CVPR 2021</strong>.
				</li>
				<li>[02/2021] One paper for <em>"Co-saliency Detection"</em> accepted by  <strong>IEEE TPAMI</strong>.
				</li>
				<li>[01/2021] One paper for <em>"Breast Lesion Segmentation"</em> accepted by  <strong>MedIA</strong>.
				</li>
				<li>[01/2021] One paper for <em>"Fundus Image Analysis Survey"</em> accepted by <strong>MedIA</strong>.
				</li>
				<li>[01/2021] One paper for <em>"Uncertainty Estimation in Multi-view Learning"</em> accepted by  <strong>ICLR 2021</strong>.
				</li>
				<li>[01/2021] One paper for <em>"Saliency Detection Survey"</em>  accepted by <strong>IEEE TPAMI</strong>.
				</li> -->

			</ul>

		</div>

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />


			<h3>
				<a id="Services-page" class="anchor" href="#Services-page" aria-hidden="true"><span
						class="octicon octicon-link"></span></a>
						<img src="sub_img/activity-logo.gif" style="height:42px;"> Professional Activities:
			</h3>
			<ul>
				<li><strong>Memberships:</strong>
					<ul>
						<li> IEEE Senior Member. </li>
						<li> Member of the IEEE Bio Imaging and Signal Processing Technical Committee (<a href="https://signalprocessingsociety.org/community-involvement/bio-imaging-and-signal-processing/bisp-tc-home" target="_blank"><strong>BISP TC</strong></a>). </li> 
					</ul> 
				</li>

				<li><strong>Associate Editor:</strong>
					<ul>
						<li> IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2020 - present. </li>
						<li> IEEE Transactions on Neural Networks and Learning Systems (<strong>IEEE TNNLS</strong>), 2022 - present. </li>
						<li> IEEE Journal of Biomedical and Health Informatics (<strong>IEEE JBHI</strong>), 2020 - present. </li>
						<li> IEEE Transactions on Artificial Intelligence (<strong>IEEE TAI</strong>), 2023 - present. </li>
						<li> Pattern Recognition (<strong>PR</strong>), 2024 - present. </li>
						<!-- <li> Scientific Reports, 2021 - present. </li> -->
						<li> Visual Intelligence, 2024 - present. </li>
						<li> Meta-Radiology, 2023 - present. </li>
						<!-- <li> IEEE Access, 2018 - present. </li> -->
					</ul>
				</li>

				<!-- <li><strong>Guest Editor:</strong>
					<ul>
						<li> IEEE JBHI, Special Issue on “<i>Foundation Models in Medical Imaging</i>”, 2024. [<a
							href="https://www.embs.org/jbhi/wp-content/uploads/sites/18/2023/09/JBHI_Foundation-Models_SI.pdf"
							target="_blank">Link</a>]</li>
						<li> IEEE TMI, Special Issue on “<i>Geometric Deep Learning in Medical Imaging</i>”, 2022. [<a
								href="https://www.embs.org/wp-content/uploads/2021/02/TMI-CFP-GDL_final.pdf"
								target="_blank">Link</a>] 
						</li>
						<li> IEEE JBHI, Special Issue on “<i>Generative Adversarial Networks in Biomedical Image Computing</i>”, 2021. [<a
								href="https://www.embs.org/jbhi/generative-adversarial-networks-in-biomedical-image-computing/"
								target="_blank">Link</a>]</li>
						<li> IEEE JBHI, Special Issue on “<i>Ophthalmic Image Analysis and Informatics</i>”, 2020.
							[<a href="https://www.embs.org/jbhi/articles/special-issue-on-ophthalmic-image-analysis-and-informatics/"
								target="_blank">Link</a>]</li>
					</ul>
				</li> -->

				<li><strong>Area Chair/Senior-PC:</strong>
					<ul>
						<li>
							MICCAI (2021-2023), IJCAI (2021), ACM MM (2024), AAAI (2022), MIDL (2022-2023), ICIP (2022-2024), BHI (2022), ICASSP (2023-2025), ISBI (2023-2025), ICLR (2025).
						</li>
					</ul>
				</li>


				<li><strong>Challenge Organizer:</strong>
					<ul>
						<li>
							"<strong>STAGE2</strong>: 2nd Structural-Functional Transition in Glaucoma Assessment" with the MICCAI 2024.  
						</li>

						<li>
							"<strong>ATLAS</strong>: A Tumor and Liver Automatic Segmentation" with the MICCAI 2023. [<a href="https://atlas-challenge.u-bourgogne.fr" target="_blank">Link</a>] 
						</li>

						<li>
							"<strong>STAGE</strong>: Structural-Functional Transition in Glaucoma Assessment" with the MICCAI 2023. [<a href="https://aistudio.baidu.com/aistudio/competition/detail/968/0/introduction" target="_blank">Link</a>]
						</li>

						<li>
							"<strong>GOALS</strong>: Glaucoma Oct Analysis and Layer Segmentation" with the MICCAI 2022.
							[<a href="https://aistudio.baidu.com/aistudio/competition/detail/230/0/introduction" target="_blank">Link</a>] 
						</li>
						<li>
							"<strong>GAMMA</strong>: Glaucoma Grading from Multi-Modality Images Challenge" with the MICCAI 2021.
							[<a href="https://gamma.grand-challenge.org/" target="_blank">Link</a>] 
							[<a href="https://arxiv.org/abs/2202.06511" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>REFUGE2</strong>: 2nd Retinal Fundus Glaucoma Challenge" with the MICCAI 2020.
							[<a href="https://refuge.grand-challenge.org" target="_blank">Link</a>]
							[<a href="https://arxiv.org/abs/2202.08994" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>ADAM</strong>: Automatic Detection challenge on Age-related Macular degeneration" with the ISBI 2020.
							[<a href="https://amd.grand-challenge.org" target="_blank">Link</a>]
							[<a href="https://arxiv.org/abs/2202.07983" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>AGE</strong>: Angle closure Glaucoma Evaluation Challenge" with the MICCAI 2019.
							[<a href="https://age.grand-challenge.org/" target="_blank">Link</a>] 
							[<a href="https://arxiv.org/abs/2005.02258" target="_blank">Summary Paper</a>]
						</li>
						<li>
							"<strong>PALM</strong>: PathologicAL Myopia detection from retinal images" with the ISBI 2019. [<a href="https://palm.grand-challenge.org" target="_blank">Link</a>] 
							[<a href="https://doi.org/10.1038/s41597-024-02911-2" target="_blank">Data Summary</a>]
						</li>
						<li>
							"<strong>REFUGE</strong>: Retinal Fundus Glaucoma Challenge" with the MICCAI 2018. 
							[<a href="https://refuge.grand-challenge.org/" target="_blank">Link</a>]
							[<a href="https://arxiv.org/abs/1910.03667" target="_blank">Summary Paper</a>]
						</li>
					</ul>
				</li>
				<li><strong>Workshop Chair:</strong>
					<ul>
						<li>MICCAI Workshop on Ophthalmic Medical Image Analysis (<strong>OMIA</strong>), 2018 - 2024. 
						[<a href="https://sites.google.com/view/omiax/home" target="_blank">Link</a>]</li>
						<li>MICCAI Workshop on Resource-Efficient Medical Image Analysis (<strong>REMIA</strong>), 2022-2023. 
						[<a href="https://miccai-remia.github.io/" target="_blank">Link</a>] </li>
					</ul>
				</li>
			</ul>
			</p>

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />

			

			<h3>
				<a id="Highlighted-Paper-pages" class="anchor" href="#Highlighted-Paper-pages" aria-hidden="true" ><span class="octicon octicon-link"></span></a>
				<img src="sub_img/paper-logo.gif" style="height:42px;"> Highlighted Publications: 
			</h3>

			<strong>More publication could be found in</strong>
				<a href="https://scholar.google.com/citations?hl=en&user=jCvUBYMAAAAJ" target="_blank">[<strong><font color="#4285F4">G</font><font color="#DB4437">o</font><font color="#F4B400">o</font><font color="#4285F4">g</font><font color="#0F9D58">l</font><font color="#DB4437">e</font> Scholar</strong>]</a>  

			<ul>

				<li> <a href="https://arxiv.org/abs/2406.16942" target="_blank"><strong>"Enhancing Al Reliability: A Foundation Model with Uncertainty Estimation for Optical Coherence Tomography based Retinal Diseases Diagnosis"</strong></a>, <br>
					Y. Peng, A. Lin, M. Wang, ..., <strong>H. Fu</strong>, and H. Chen, <br>  
					<i><strong>Cell Reports Medicine</strong>, 2024.</i> <a href="https://github.com/yuanyuanpeng0129/FMUE" target="_blank">[Code]</a>
					</li> 


				<li> <a href="https://arxiv.org/abs/2408.13161" target="_blank"><strong>"Say No to Freeloader: Protecting Intellectual Property of Your Deep Model"</strong></a>, <br>
					L. Wang, M. Wang, <strong>H. Fu</strong>, and D. Zhang, <br>  
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2024.</i> <a href="https://github.com/LyWang12/CUPI-Domain" target="_blank">[Code]</a>
					</li> 

				<li> <a href="https://arxiv.org/abs/2205.12857" target="_blank"><strong>"Structure Unbiased Adversarial Model for Medical Image Translation"</strong></a>,<br>
					T. Zhang, S. Zheng, J. Cheng, X. Jia, J. Bartlett, X. Cheng, Z. Qiu, <strong>H. Fu</strong>, J. Liu, A. Leonardis, and J. Duan,<br>  
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2024.</i> <a href="https://traceable-translation.github.io/" target="_blank">[Online Demo]</a>
				  </li> 


				  <li><a href="https://doi.org/10.1186/s13073-024-01283-x" target="_blank"><strong>"Unsupervised spatially embedded deep representation of spatial transcriptomics"</strong></a>,<br>  
					 H. Xu, <strong>H. Fu</strong>, Y. Long, K. S. Ang, R. Sethi, K. Chong, M. Li, R. Uddamvathanak, H. K. Lee, J. Ling, A. Chen, L. Shao, L. Liu and J. Chen,<br>  
					<i><strong>Genome Medicine</strong>, 2024.</i> 
					<a href="https://github.com/JinmiaoChenLab/SEDR/" target="_blank">[Code]</a>
					<a href="https://github.com/JinmiaoChenLab/SEDR_analyses/" target="_blank">[Analysis Code]</a> 
				  </li>

				<li> <a href="https://arxiv.org/abs/2406.12536" target="_blank"><strong>"ViDSOD-100: A New Dataset and A Baseline Model for RGB-D Video Salient Object Detection"</strong></a>, <br>
					J. Lin, L. Zhu, J. Shen, <strong>H. Fu</strong>,  Q. Zhang, and L. Wang, <br>
					<i>International Journal of Computer Vision (<strong>IJCV</strong>), 2024.</i>
					<a href="https://github.com/jhl-Det/RGBD_Video_SOD" target="_blank">[Code]</a> 
				  </li> 

				  <li> <a href="https://doi.org/10.1038/s41746-024-01292-5" target="_blank"><strong>"Early Detection of Dementia through Retinal Imaging and Trustworthy AI"</strong></a>, <br>
					J. Hao, W. Kwapong, T. Shen, <strong>H. Fu</strong>, ...,  and Y. Zhao, <br>
					<i><strong>npj Digital Medicine</strong>, 2024.</i> 
					<a href="https://github.com/iMED-Lab/Eye-AD" target="_blank">[Code]</a> 
				  </li>    
				  
				<li><a href="https://doi.org/10.1038/s41467-023-42444-7" target="_blank"><strong>"Uncertainty-inspired Open Set Learning for Retinal Anomaly Identification"</strong></a>,   <br>
					M. Wang, T. Lin, L. Wang, ..., H. Chen, and <strong>H. Fu</strong>,<br>
					
					<i><strong>Nature Communications</strong>, 2023.</i> 
					<a href="https://github.com/LooKing9218/UIOS" target="_blank">[Code]</a>
				  </li>

			  <li><a href="https://www.nature.com/articles/s42256-023-00652-2" target="_blank"><strong>"Federated Benchmarking of Medical Artificial Intelligence with MedPerf"</strong></a>, <br>
				A. Karargyris, R. Umeton, ...,  <strong>H. Fu</strong>, ..., S. Bakas, and P. Mattson,<br>
			  <i><strong>Nature Machine Intelligence</strong>, 2023.</i> 
			  <a href="https://github.com/mlcommons/medperf" target="_blank">[Code]</a> 
			</li> 
			  <li><a href="https://www.nature.com/articles/s41467-023-36796-3" target="_blank"><strong>"Spatially informed clustering, integration, and deconvolution of spatial transcriptomics with GraphST"</strong></a>,<br>
				Y. Long, K. S. Ang, ..., <strong>H. Fu</strong>, ..., and J. Chen,<br>
			<i><strong>Nature Communications</strong>, 2023.</i> 
			<a href="https://github.com/JinmiaoChenLab/DeepST" target="_blank">[Code]</a> 
		  </li>

		  

		  <li><a href="https://arxiv.org/abs/2205.15469" target="_blank"><strong>"GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector"</strong></a>,<br>
			P. Zheng, <strong>H. Fu</strong>, D.-P. Fan, Q. Fan, J. Qin, Y.-W. Tai, C.-K. Tang, and L. V. Gool,<br>  
			<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2023.</i>
			<a href="https://github.com/ZhengPeng7/GCoNet_plus" target="_blank">[Code]</a>
		  </li> 
		   

			  <li><a href="https://arxiv.org/abs/2204.11423" target="_blank"><strong>"Trusted Multi-View Classification with Dynamic Evidential Fusion"</strong></a>,
				<br>
				Z. Han, C. Zhang, <strong>H. Fu</strong>, and J. T. Zhou,<br>
				<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2023.</i> 
				<a href="https://github.com/hanmenghan/TMC" target="_blank">[Code]</a>
 
			  </li>
			  
				<li><a href="https://arxiv.org/abs/2202.04861" target="_blank"><strong>"Consistency and Diversity induced Human Motion Segmentation"</strong></a>,<br>
					T. Zhou, <strong>H. Fu</strong>, C. Gong, L. Shao, F. Porikli, H. Ling, and J. Shen,</em><br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2023.</i>  
				  </li> 
			
				  
				<li><a href="https://arxiv.org/abs/2007.03380" target="_blank"><strong>"Re-thinking Co-Salient Object Detection"</strong></a>, <br>
					D.-P. Fan, T. Li, Z. Lin, G.-P. Ji, D. Zhang, M.-M. Cheng, <strong>H. Fu</strong>, and J. Shen, <br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2022.</i> 
					<a href="https://dengpingfan.github.io/papers/[2021][TPAMI]CoSOD3k_Chinese.pdf" target="_blank">[Chinese
						version]</a> 
					<a href="https://github.com/DengPingFan/CoEGNet" target="_blank">[Code]</a>
 
				</li>

				<li><a href="https://arxiv.org/abs/1904.09146" target="_blank"><strong>"Salient Object Detection in the Deep Learning Era: An In-Depth Survey",</strong></a><br>
					W. Wang, Q. Lai, <strong>H. Fu</strong>, J. Shen, H. Ling, and R. Yang,<br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2022.</i>
					<a href="https://github.com/wenguanwang/SODsurvey" target="_blank">[Project]</a>  
 
				</li>

				<li><a href="https://arxiv.org/abs/2011.06170" target="_blank"><strong>"Deep Partial Multi-View Learning"</strong></a>,<br>
					C. Zhang, Y. Cui, Z. Han, J. T. Zhou, <strong>H. Fu</strong>, and Q. Hu,<br>
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2022.</i>
					
					<a href="https://github.com/hanmenghan/CPM_Nets" target="_blank">[Code]</a>  
		 
				</li>   

				<!-- <li><a href="https://arxiv.org/abs/2101.09864" target="_blank"><strong>"Applications of Deep Learning in Fundus Images: A Review"</strong></a>,<br>
					T. Li, W. Bo, C. Hu, H. Kang, H. Liu, K. Wang, and <strong>H. Fu</strong>,<br> 
					<i>Medical Image Analysis (<strong>MedIA</strong>), 2021.</i>
					
					<a href="https://github.com/nkicsl/Fundus_Review" target="_blank">[Project]</a>
					 
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>)
				</li>  -->
 
				<li><a href="https://www.researchgate.net/publication/328479701_Generalized_Latent_Multi-View_Subspace_Clustering" target="_blank"><strong>"Generalized Latent Multi-view Subspace Clustering"</strong></a>,<br>
					C. Zhang, <strong>H. Fu</strong>, Q. Hu, X. Cao, Y. Xie, D. Tao, and
          D. Xu, <br> 
					<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>IEEE TPAMI</strong>), 2020.</i> 
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LMSC_CVPR2017_Zhang.rar">[Code]</a> 
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/ORL_mtv.rar">[Data]</a>
					 
					 
				</li>  

				<li> <a href="https://doi.org/10.1007/s11263-020-01307-0" target="_blank"><strong>"Tensorized Multi-View Subspace Representation Learning"</strong></a>,   <br>
					C. Zhang, <strong>H. Fu</strong>, J. Wang, Q. Hu, X. Cao, and W. Li,  <br>
					
					<i>International Journal of Computer Vision (<strong>IJCV</strong>), 2020.</i> 
					<a href="http://cic.tju.edu.cn/faculty/zhangchangqing/code/LT-MSC-ICCV15-final.rar">[Code]</a>
				  </li>
					
				<!-- <li><a href="https://arxiv.org/abs/2004.14133" target="_blank"><strong>"Inf-Net: Automatic COVID-19 Lung Infection Segmentation from CT Images"</strong></a>,<br>
					D.-P. Fan, T. Zhou, G.-P. Ji, Y. Zhou, G. Chen, <strong>H. Fu</strong>, J. Shen, and L. Shao, <br>
					<i>IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2020.</i>
					
					<a href="https://github.com/DengPingFan/Inf-Net" target="_blank">[Code]</a>
					 
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>, 
					<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=wqLkMlos2DIJ.2022" target="_blank"><hl_color><em>Top-20 Most Cited Paper within 5 Years in IEEE TMI 2022</em></hl_color></a>, 
					<a href="https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=42" target="_blank"><hl_color><em>Top-50 Most Frequently Accessed Documents in IEEE TMI"</em></hl_color></a>)
				</li>  
 

				<li><a href="https://arxiv.org/abs/1903.02740" target="_blank"><strong>"CE-Net: Context Encoder Network for 2D Medical Image Segmentation"</strong></a>,<br>
					Z. Gu, J. Cheng, <strong>H. Fu</strong>, K. Zhou, H. Hao, Y. Zhao, T. Zhang, S. Gao, and J. Liu,<br>

					<i>IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2019.</i>
					
					<a href="https://github.com/Guzaiwang/CE-Net" target="_blank">[Code]</a>
					 
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>, 
					<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=wqLkMlos2DIJ.2022" target="_blank"><hl_color><em>Top-10 Most Cited Paper within 5 Years in IEEE TMI 2022</em></hl_color></a>,
					<a href="https://ieeexplore.ieee.org/xpl/topAccessedArticles.jsp?punumber=42" target="_blank"><hl_color><em>Top-50 Most Frequently Accessed Documents in IEEE TMI"</em></hl_color></a>)
				</li> 

				<li><a href="https://arxiv.org/abs/1801.00926" target="_blank"><strong>"Joint Optic Disc and Cup Segmentation Based on Multi-label Deep Network and Polar
					Transformation"</strong></a>,<br>
					<strong>H. Fu</strong>, J. Cheng, Y. Xu, D. W. K. Wong, J. Liu, and X. Cao, <br>

					<i>IEEE Transactions on Medical Imaging (<strong>IEEE TMI</strong>), 2018.</i>
					
					<a href="https://github.com/HzFu/MNet_DeepCDR" target="_blank">[Code]</a>
				 
					(<hl_color><em>ESI Highly Cited Paper</em></hl_color>, 
					<a href="https://scholar.google.com/citations?hl=en&view_op=list_hcore&venue=wqLkMlos2DIJ.2022" target="_blank"><hl_color><em>Top-20 Most Cited Paper within 5 Years in IEEE TMI 2022</em></hl_color></a>)
				</li>   -->

			</ul> 

			 

			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />

			<h3>
				<a id="awards-pages" class="anchor" href="#awards-pages" aria-hidden="true" ><span class="octicon octicon-link"></span></a>
				<img src="sub_img/award-logo.gif" style="height:42px;"> Recognitions & Awards: 
			</h3>
			<ul> 


				<li> 
					2020-2024: <strong>World's Top 2% Scientists List</strong>, identified by Stanford/Elsevier (in category Artificial Intelligence & Image Processing).
					<a href="https://topresearcherslist.com" target="_blank">[Link]</a>
				</li>

				<li>
					2024: <strong>Best Paper Award</strong> of Ophthalmic Medical Image Analysis (OMIA) Workshop in MICCAI. 
				</li>

				<li>
					2024: Finalist of the Young Scientist Publication Impact Award in MICCAI.
				</li>

				<li>
					2024: <strong>Honorable Mention Award</strong> by Computational Visual Media Journal. 
					<a href="https://link.springer.com/journal/41095/updates/26965690" target="_blank">[Link]</a>
				</li> 

				<li>
					2024: <strong>Collaborative Paper Award</strong> by Biomedical Research Council (BMRC), A*STAR.
				</li>
				<li>
					2024: <strong>Outstanding Presentation</strong> under the Computing, Data and Digital Sciences track at A*STAR CDF Day, 2024.
				</li>
				<li>
					2023: <strong>Achievement Award</strong>  of  2023 TOP 100 Benchmarks & Evaluation by International Open Benchmark Council.
				</li>
				<li>
					2023: <strong>Best Paper Award</strong> of  Distributed, Collaborative and Federated Learning (DeCAF) Workshop in MICCAI. 
				</li>
				
				<li>
					2022: <strong>Best Paper Award</strong> of Ophthalmic Medical Image Analysis (OMIA) Workshop in MICCAI. 
				</li>
				<li>
					2022: <strong>Best Paper Runner-up Award</strong> of Resource-Efficient Medical Image Analysis (REMIA) Workshop in MICCAI. 
				</li>
				
				<li>
					2021: <strong>Best Paper Award</strong> in IEEE International Conference on Multimedia & Expo (ICME). 
					<a href="http://2021.ieeeicme.org/2021.ieeeicme.org/best_paper_awards.html" target="_blank">[Link]</a>
				</li> 
				
				<li>
					2021: Finalist of the Young Scientist Publication Impact Award in MICCAI.
				</li>
				<li>
					2021: <strong>Most Influential Paper (Application) Award</strong> in Jittor Developer Conference.
				</li>
				<!-- <li>
					2020-2022: IEEE TMI Distinguished Reviewer Gold Level.
				</li>
				<li>
					2021: Outstanding Reviewer in CVPR.
				</li> -->
				<li>
					2014 China Computer Federation (CCF) Outstanding Dissertation Nomination.
					<a href="https://www.ccf.org.cn/c/2014-12-14/647609.shtml" target="_blank">[Link]</a>
				</li>

			</ul>
			<div align="right">
				<a href="#top-page">[<b>Back to top</b>]</a>
			  </div>
			<hr />
   
			 

	<a href="https://www.revolvermaps.com/livestats/5c6hj26tc4d/"><img src="//rf.revolvermaps.com/h/m/a/0/ff0000/128/0/5c6hj26tc4d.png" width="256" height="128" alt="Map" style="border:0;"></a>

		</section>

	</div>
</body>

</html>
